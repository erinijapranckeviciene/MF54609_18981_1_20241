{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41375591-b8c2-4b9f-997b-2156eb71c126",
   "metadata": {},
   "source": [
    "# Text processing with RNN using IMDB reviews dataset.\n",
    "\n",
    "#### Run cells and answer following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4fb87b-6c66-475f-a1f9-2be95ffc6686",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 1:\n",
    "\n",
    "#### The dense model below was built using 1 Ngram model and classification accuracy on test data achieved is ~0.888. Reuse the same model with 2 Ngram option. What do you have to change? What accuracy do you achieve on test data? Is it better or worse than 1 Ngram? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830da14c-1343-4dcc-a507-83426e4651a0",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "\n",
    "#### Find the funtion to retrieve the created vocabulary ( reference: https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization). Retrieve vocabulary for 2 Ngram model and display and count how many times you see a phrase that contains word 'terrible'.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbbca10-83c0-470e-8649-7ffebebab637",
   "metadata": {},
   "source": [
    "## Question 3:\n",
    "\n",
    "#### In the last part with MultiHeadAttention layer what regularization method could we use to reduce training when performance starts oscilating on the validation set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfda8f00-dc60-4a5a-9a07-62760759945f",
   "metadata": {},
   "source": [
    "## Question 4 optional: \n",
    "\n",
    "#### In the last part it would be interesting to access and inspect Embedding and MultiHeadAttention layers to understand their structure. But the IMDB dataset is very complex. How can we create a very simple two or four sentences dataset to work with the model and how to access those layers to inspect their weights? The most important thing is that we understand why we are choosing one or the other architecture.     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e779907c-2969-4cde-aaac-8cb9bd78e295",
   "metadata": {},
   "source": [
    "## Prepare IMDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a7ee70-e2cc-43d9-bbcf-fb4147f3c0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, shutil, random\n",
    "from tensorflow import keras\n",
    "\n",
    "batch_size = 32\n",
    "train_ds = keras.utils.text_dataset_from_directory(\"aclImdb/train\", batch_size=batch_size )\n",
    "val_ds = keras.utils.text_dataset_from_directory(\"aclImdb/val\", batch_size=batch_size)\n",
    "test_ds = keras.utils.text_dataset_from_directory(\"aclImdb/test\", batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a74a99-e19c-40a0-8ca0-1e71711319b5",
   "metadata": {},
   "source": [
    "#### Inspect the dataset read from directory files \n",
    "Displaying the shapes and dtypes of the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87d94172-d37b-45d0-b9be-81f1d488fa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (32,)\n",
      "inputs.dtype: <dtype: 'string'>\n",
      "targets.shape: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor(b'An entertaining and substantive film, Non-Stop has drawn deserving comparisons with \"Run Lola Run\". The film quickly develops into a chase sequence, during which the viewers learn about the three main characters through flashbacks and daydream sequences. The chase serves not as as a fast-paced climax, but as a journey that makes up the majority of the film. During the \"run\" we see the characters grow and momentarily forget about their dreary lives, about the \"macho\" roles they\\'ve bought into, and eventually forgetting about why they started running in the first place. Much like fighting provided a \"clarity\" for the characters in \"Fight Club,\" running provides this film\\'s characters with a means to step away from the false values that we all allow society to create for us. Their running serves as way to truly taste life from an unclouded perspective, and all three find some level of clarity and joy in the process.<br /><br />My appreciation and enjoyment only wavered slightly in the ending of the film, where instead of learning from their experience, the characters seem to revert to acting out those false macho roles I thought they had escaped from through their journey.<br /><br />Still, the only true problem with this film is that it wasn\\'t distributed outside Japan sooner.', shape=(), dtype=string)\n",
      "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds:\n",
    "    print(\"inputs.shape:\", inputs.shape)\n",
    "    print(\"inputs.dtype:\", inputs.dtype)\n",
    "    print(\"targets.shape:\", targets.shape)\n",
    "    print(\"targets.dtype:\", targets.dtype)\n",
    "    print(\"inputs[0]:\", inputs[0])\n",
    "    print(\"targets[0]:\", targets[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cf5dac-c429-480a-9545-7d20d1f3bfb9",
   "metadata": {},
   "source": [
    "#### Keep only text in text_only_train_ds. Use only text data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1f00f27-1536-48d0-b944-c749a0433e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (32,)\n",
      "inputs.dtype: <dtype: 'string'>\n",
      "inputs[0]: tf.Tensor(b'When this movie was first shown on television I had high hopes that we would finally have a decent movie about World War I as experienced by American soldiers. Unfortunately this is not it.<br /><br />It should have been a good movie about WWI. Even though it was made for television it is obvious that a real effort was made to use appropriate equipment and props. But the writing and directing are badly lacking, even though the makers of this movie obviously borrowed freely from quite a few well made war movies. War movie clich\\xc3\\xa9s abound such as the arrogant general who apparently does not care a flip about the lives of his men. When will Hollywood realize that, even though there have been plenty of bad generals, most combat unit generals have seen plenty of combat themselves and are not naive about what the average grunt experiences? The first part of this movie appeared to be \"Paths of Glory\" with American uniforms. Except that \"Paths of Glory\" was emotionally gripping. Later on there was Chamberlain\\'s charge (except uphill) from \"Gettysburg\" and even the capture of the American soldier by a ring of enemy soldiers from \"The Thin Red Line\". But in \"The Thin Red Line\" the soldier was alone when captured. In this movie a ring forms around the new prisoner in the middle of a battle.<br /><br />If this movie used a military adviser they ignored him. Even though the actors (and I never could forget they were actors while watching) mouthed military tactics I didn\\'t see very much of it. The American soldiers would stand up to be shot while the Germans attacked. And the infamous Storm Troopers, who were apparently blind, appeared to use no tactics whatsoever in their attack. In the real war, the tactics were what made storm troopers so effective. But the silliest scene was the attack of the German Flamethrowers. In this scene the German flamethrower operators walked in a broad line towards the defending Americans. If that had been real they would never have gotten close enough to use their flamethrowers before they had all been dropped by the defender\\'s bullets.<br /><br />Okay, so most war movies are unrealistic when it comes to the tactics shown. But it is still disappointing. But what really turned me off to this flick was the typical anti-war anti-military angle that movie makers seem to think is important. True, war is hell. But most American soldiers, even though they grumble and gripe, tend to believe in what they are doing and can be rather gung-ho about it. My Grandfather served in World War I. And even though he died four years before I was born I have been told how proud he was of his service.', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# This function returns only data part without target \n",
    "# to create a new dataset that will be used to create dictionary\n",
    "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
    "for inputs in text_only_train_ds:\n",
    "    print(\"inputs.shape:\", inputs.shape)\n",
    "    print(\"inputs.dtype:\", inputs.dtype)\n",
    "    print(\"inputs[0]:\", inputs[0])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a904102-ae81-4b24-bd9a-edca24f87851",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "# Text vectorization layer creates a structure that will populate with textual data\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization\n",
    "# This layer performs text standardization, splitting it into Ngrams - single or pairs of words\n",
    "# It prepares output according to output mode\n",
    "text_vectorization = TextVectorization( max_tokens=20000, output_mode=\"multi_hot\")\n",
    "\n",
    "# Use text_only_train_ds to create a dictionary of words that are in IMDB reviews,\n",
    "# the vocabulary is limited by 20000 (adapt() method) \n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "# Here datasets are created where the text in the string is converted \n",
    "# to the representation of 20000 dimensional vectors in which a presence of word in \n",
    "# the text is marked by 1 and absence by 0. This is done for train, validation and test. \n",
    "binary_1gram_train_ds = train_ds.map( lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "binary_1gram_val_ds = val_ds.map( lambda x, y: (text_vectorization(x), y),num_parallel_calls=4)\n",
    "binary_1gram_test_ds = test_ds.map( lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cce6611-6109-4549-813c-2b313be7818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (32, 20000)\n",
      "inputs.dtype: <dtype: 'float32'>\n",
      "targets.shape: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
      "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in binary_1gram_train_ds:\n",
    "    print(\"inputs.shape:\", inputs.shape)\n",
    "    print(\"inputs.dtype:\", inputs.dtype)\n",
    "    print(\"targets.shape:\", targets.shape)\n",
    "    print(\"targets.dtype:\", targets.dtype)\n",
    "    print(\"inputs[0]:\", inputs[0])\n",
    "    print(\"targets[0]:\", targets[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dbe81e-093b-416a-9518-fdadab483eaf",
   "metadata": {},
   "source": [
    "#### This is function creates model from Listing 11.5\n",
    "Our model-building utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "712388fd-69bb-46f1-bc5a-e9e1e4fcc960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# This is dense model\n",
    "def get_model(max_tokens=20000, hidden_dim=16):\n",
    "    inputs = keras.Input(shape=(max_tokens,))\n",
    "    x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "935fbf5e-edf7-49a9-a0d5-d8170fb580b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                320016    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320033 (1.22 MB)\n",
      "Trainable params: 320033 (1.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8988a824-2cab-4785-827d-50bf2177af53",
   "metadata": {},
   "source": [
    "#### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b102d314-fb12-4597-b908-90c8a5e345b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 18:49:19.326636: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f820840c350 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-16 18:49:19.326669: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2024-01-16 18:49:19.337653: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-16 18:49:19.366483: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1705448959.406738   31625 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f83102a6690>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cache() is a dataset method that saves the dataset elements in memory or disk and reuses them when called \n",
    "callbacks = [ keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\", save_best_only=True) ]\n",
    "model.fit(binary_1gram_train_ds.cache(), validation_data=binary_1gram_val_ds.cache(), verbose=0, epochs=10, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "850fdbf9-6376-4c5b-b16d-061bdb8bb17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 3ms/step - loss: 0.2856 - accuracy: 0.8881\n",
      "Test acc: 0.888\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on test data\n",
    "model = keras.models.load_model(\"binary_1gram.keras\")\n",
    "print(f\"Test acc: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb5066a-533d-431d-b24d-3aca4361a22a",
   "metadata": {},
   "source": [
    "## Different output mode -  integer sequence datasets\n",
    "\n",
    "#### LSTM layer with 4 units gives worse that 2 Ngram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9ad80d17-a24d-45eb-bdfd-4380d91ffcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# max_length is a length of the vector that encodes text\n",
    "# 250 size gave ~0.85 on test data\n",
    "# 600 with 4 LSTM units does not train at all\n",
    "# the reviews are about 300 words\n",
    "max_length = 300 \n",
    "max_tokens = 20000\n",
    "text_vectorization = layers.TextVectorization( max_tokens=max_tokens, output_mode=\"int\", output_sequence_length=max_length)\n",
    "\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5e159f4-82f5-4552-aa93-ef84fdad4af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 300)\n",
      "tf.Tensor(\n",
      "[  275    10  3286    17    11    20  1052    10   417     8  4824     3\n",
      "  2755    37    84  7536    19   845     9     7    10   220  2625     2\n",
      "  1508    21     4    88   472   287     6    83    49    55   117    17\n",
      "    56     1   173    32    10    69   130    62    62    50    39    56\n",
      "   278    14  1067    21    11    20     3     9   125  4166    70   241\n",
      "    10     1  1395  3142     9    46    45    23    69    85   948   775\n",
      "   583     3     5   257     4   226    12    76  3522    23    21   123\n",
      " 19844    68     9     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0], shape=(300,), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in int_train_ds:\n",
    "    print(inputs.shape)\n",
    "    print(inputs[0])\n",
    "    print(targets[0])\n",
    "    # With this test_input variable verify tf.one_hot() transformation\n",
    "    test_input=inputs[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a04cee-0005-496a-9c60-bd534888d200",
   "metadata": {},
   "source": [
    "#### Try RNN for text classification using integer feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd6227db-8275-4e18-8881-e210aa834266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(300, 20000), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.one_hot(test_input, depth=max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a550ec6-738d-4a54-9753-ddc974257b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, None, 20000), dtype=tf.float32, name=None), name='tf.one_hot/one_hot:0', description=\"created by layer 'tf.one_hot'\")\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " tf.one_hot (TFOpLambda)     (None, None, 20000)       0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 10)                800440    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 800451 (3.05 MB)\n",
      "Trainable params: 800451 (3.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The sizes of layers are minimized in order to run\n",
    "import tensorflow as tf\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "# Here will be binary input as test_input\n",
    "embedded = tf.one_hot(inputs, depth=max_tokens)\n",
    "print(embedded)\n",
    "\n",
    "# RNN layer \n",
    "# NOT USE TOO BIG MODEL : x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "# When units=4 the model runs. \n",
    "x = layers.LSTM(10)(embedded)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc5c6353-38fd-4d28-a007-b3d3638d7cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ keras.callbacks.ModelCheckpoint(\"int_lstm.keras\", save_best_only=True) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da28a0b0-0953-4a36-8558-9b966ba90dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 20:28:54.352918: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-01-16 20:28:55.343696: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fe0c012b120 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-16 20:28:55.343753: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2024-01-16 20:28:55.354269: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1705454935.397039   45236 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 33s 49ms/step - loss: 0.6927 - accuracy: 0.5084 - val_loss: 0.6927 - val_accuracy: 0.5014\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 30s 49ms/step - loss: 0.6865 - accuracy: 0.5331 - val_loss: 0.6548 - val_accuracy: 0.6198\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 0.6108 - accuracy: 0.6962 - val_loss: 0.5773 - val_accuracy: 0.7280\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 0.5302 - accuracy: 0.7718 - val_loss: 0.4619 - val_accuracy: 0.8224\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 31s 49ms/step - loss: 0.4617 - accuracy: 0.8257 - val_loss: 0.4866 - val_accuracy: 0.7986\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 30s 49ms/step - loss: 0.4305 - accuracy: 0.8456 - val_loss: 0.4157 - val_accuracy: 0.8518\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 31s 49ms/step - loss: 0.3903 - accuracy: 0.8658 - val_loss: 0.3834 - val_accuracy: 0.8582\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 30s 49ms/step - loss: 0.3296 - accuracy: 0.8850 - val_loss: 0.3142 - val_accuracy: 0.8778\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 0.2776 - accuracy: 0.8967 - val_loss: 0.3575 - val_accuracy: 0.8774\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 0.2551 - accuracy: 0.9079 - val_loss: 0.7286 - val_accuracy: 0.6830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fe1d03d5f50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c4768d8c-f61f-4bf2-ba39-e150905fe64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 22s 27ms/step - loss: 0.3266 - accuracy: 0.8671\n",
      "Test acc: 0.867\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"int_lstm.keras\")\n",
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc688cfd-e185-4428-b0c3-8ea840d24896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 20s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(int_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "883ddcd9-8ffa-4be3-85fd-3909e0b41434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50074637]\n",
      " [0.9223024 ]\n",
      " [0.92039317]\n",
      " ...\n",
      " [0.10627599]\n",
      " [0.04852633]\n",
      " [0.9195446 ]]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3bdbaba0-e6ab-482b-95ca-504510d7551a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 1]\n",
      "[array([0, 1]), array([12590, 12410])]\n"
     ]
    }
   ],
   "source": [
    "predicted=np.array([int(x>0.5) for x in np.concatenate(pred) ] )\n",
    "print(predicted)\n",
    "unique, counts = np.unique(predicted, return_counts=True)\n",
    "print([unique, counts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1c430f23-5a70-4fa4-8b76-04e01739f218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 0 0 1]\n",
      "[array([0, 1]), array([12500, 12500])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# This displays the contents of the dataset\n",
    "# list(int_test_ds)\n",
    "# Collect targets to use in confusion table\n",
    "target_arr=[]\n",
    "for inputs, targets in int_test_ds:\n",
    "    target=[int(x) for x in targets]\n",
    "    target_arr.append(target)\n",
    "    \n",
    "actual=np.concatenate(target_arr)\n",
    "print(actual)\n",
    "unique, counts = np.unique(actual, return_counts=True)\n",
    "print([unique, counts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "545f8928-7fa7-4c84-bc64-a0ed544f0c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[6289, 6211],\n",
       "       [6301, 6199]], dtype=int32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show confusion table\n",
    "# Why confusion table shows different accuracy than accuracy of model evaluate? \n",
    "# Need to investigate, but leaving it for later now. \n",
    "tf.math.confusion_matrix(actual, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4321d6-0aad-43ea-b4e7-dd40c65c8d13",
   "metadata": {},
   "source": [
    "#### Try to use Enbedding layer for the previous problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6e5ae1b7-b150-4e71-b36d-d2a50af015c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, None, 256)         5120000   \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 35)                40880     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 35)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 36        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5160916 (19.69 MB)\n",
      "Trainable params: 5160916 (19.69 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000\n",
    "embed_dim = 256\n",
    "\n",
    "# ignore from FC book Ch.11 Listing 11.22\n",
    "#num_heads = 2\n",
    "#dense_dim = 32\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "x = layers.Embedding(vocab_size, embed_dim)(inputs)\n",
    "\n",
    "x = layers.LSTM(35)(x)\n",
    "\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# Maybe optimizer could be different? \n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5a543783-1c36-418a-a4fc-3480e34873f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 35s 53ms/step - loss: 0.6940 - accuracy: 0.5092 - val_loss: 0.6926 - val_accuracy: 0.5072\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 17s 27ms/step - loss: 0.6900 - accuracy: 0.5214 - val_loss: 0.6915 - val_accuracy: 0.5118\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 13s 21ms/step - loss: 0.6819 - accuracy: 0.5552 - val_loss: 0.6639 - val_accuracy: 0.6100\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 11s 17ms/step - loss: 0.6382 - accuracy: 0.6525 - val_loss: 0.6262 - val_accuracy: 0.7140\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 11s 18ms/step - loss: 0.5838 - accuracy: 0.7214 - val_loss: 0.6064 - val_accuracy: 0.6988\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 0.5471 - accuracy: 0.7571 - val_loss: 0.6596 - val_accuracy: 0.6798\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 11s 17ms/step - loss: 0.5201 - accuracy: 0.7754 - val_loss: 0.5918 - val_accuracy: 0.7236\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 12s 19ms/step - loss: 0.4876 - accuracy: 0.7994 - val_loss: 0.5266 - val_accuracy: 0.7796\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 10s 17ms/step - loss: 0.4652 - accuracy: 0.8115 - val_loss: 0.5297 - val_accuracy: 0.7848\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 0.4368 - accuracy: 0.8280 - val_loss: 0.5337 - val_accuracy: 0.7918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fdf66b05c10>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [ keras.callbacks.ModelCheckpoint(\"int_embed_lstm.keras\", save_best_only=True) ]\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "35c81333-bf99-4133-890a-d0f2770655fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 6s 7ms/step - loss: 0.5444 - accuracy: 0.7682\n",
      "Test acc: 0.768\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"int_embed_lstm.keras\")\n",
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a976e038-b600-4d5f-a90c-7febde85996a",
   "metadata": {},
   "source": [
    "### The more complex architecture the poorer results are"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156900ad-5156-4836-bee8-756853109138",
   "metadata": {},
   "source": [
    "#### Model that uses Encoder and MultiHeadAttention layers ( by some analogy to Listing 11.22 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9e6782b0-74ce-49af-a447-73a39f62a7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_17 (InputLayer)       [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding_15 (Embedding)    (None, None, 256)            5120000   ['input_17[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (M  (None, None, 256)            1314816   ['embedding_15[0][0]',        \n",
      " ultiHeadAttention)                                                  'embedding_15[0][0]']        \n",
      "                                                                                                  \n",
      " global_max_pooling1d_9 (Gl  (None, 256)                  0         ['multi_head_attention_10[0][0\n",
      " obalMaxPooling1D)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)        (None, 256)                  0         ['global_max_pooling1d_9[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_19 (Dense)            (None, 1)                    257       ['dropout_15[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6435073 (24.55 MB)\n",
      "Trainable params: 6435073 (24.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# What can we do to improve? Here we dont have any RNN, just transformations \n",
    "\n",
    "vocab_size = 20000\n",
    "embed_dim = 256\n",
    "\n",
    "# from FC book Ch.11 Listing 11.22\n",
    "# num_heads = 2 - acheved 8.69\n",
    "# Lets try more heads/words\n",
    "# With 4 heads 8.73 , just a bit , with 5 heads 8.70\n",
    "# Still worse than a simpler method. \n",
    "num_heads = 5\n",
    "dense_dim = 32\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "x = layers.Embedding(vocab_size, embed_dim)(inputs)\n",
    "\n",
    "# try to add attention \n",
    "x = layers.MultiHeadAttention( num_heads=num_heads, key_dim=embed_dim)(x,x)\n",
    "\n",
    "# This layer is needed - what it does? \n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29275d7d-bd8e-4471-b5cb-8e1a98c039e0",
   "metadata": {},
   "source": [
    "#### Use model with attention , it really improved from previous, but not compared to more simple model of 2 Ngram.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f103cc80-1ae9-4d98-92fa-f0546e9cc4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 47s 74ms/step - loss: 0.6941 - accuracy: 0.5085 - val_loss: 0.6849 - val_accuracy: 0.5162\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 36s 57ms/step - loss: 0.4734 - accuracy: 0.7649 - val_loss: 0.3398 - val_accuracy: 0.8568\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 34s 55ms/step - loss: 0.3019 - accuracy: 0.8749 - val_loss: 0.3079 - val_accuracy: 0.8776\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 33s 53ms/step - loss: 0.2410 - accuracy: 0.9054 - val_loss: 0.3145 - val_accuracy: 0.8804\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 33s 52ms/step - loss: 0.2062 - accuracy: 0.9214 - val_loss: 0.3313 - val_accuracy: 0.8784\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 33s 52ms/step - loss: 0.1805 - accuracy: 0.9319 - val_loss: 0.3452 - val_accuracy: 0.8822\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 32s 52ms/step - loss: 0.1598 - accuracy: 0.9420 - val_loss: 0.3696 - val_accuracy: 0.8740\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.1436 - accuracy: 0.9487 - val_loss: 0.3917 - val_accuracy: 0.8798\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 32s 52ms/step - loss: 0.1305 - accuracy: 0.9543 - val_loss: 0.4057 - val_accuracy: 0.8788\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.1175 - accuracy: 0.9593 - val_loss: 0.4968 - val_accuracy: 0.8616\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.1063 - accuracy: 0.9628 - val_loss: 0.4901 - val_accuracy: 0.8760\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.0963 - accuracy: 0.9685 - val_loss: 0.5182 - val_accuracy: 0.8720\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.0895 - accuracy: 0.9692 - val_loss: 0.5993 - val_accuracy: 0.8576\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.0795 - accuracy: 0.9732 - val_loss: 0.5734 - val_accuracy: 0.8728\n",
      "Epoch 15/20\n",
      "625/625 [==============================] - 32s 52ms/step - loss: 0.0704 - accuracy: 0.9769 - val_loss: 0.6149 - val_accuracy: 0.8746\n",
      "Epoch 16/20\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.0615 - accuracy: 0.9803 - val_loss: 0.6740 - val_accuracy: 0.8684\n",
      "Epoch 17/20\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.0546 - accuracy: 0.9815 - val_loss: 0.7325 - val_accuracy: 0.8684\n",
      "Epoch 18/20\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.0479 - accuracy: 0.9861 - val_loss: 0.8021 - val_accuracy: 0.8706\n",
      "Epoch 19/20\n",
      "625/625 [==============================] - 32s 50ms/step - loss: 0.0427 - accuracy: 0.9869 - val_loss: 0.8933 - val_accuracy: 0.8618\n",
      "Epoch 20/20\n",
      "625/625 [==============================] - 32s 50ms/step - loss: 0.0366 - accuracy: 0.9887 - val_loss: 0.8854 - val_accuracy: 0.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fdf76216550>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [ keras.callbacks.ModelCheckpoint(\"attention.keras\", save_best_only=True) ]\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ca3920ff-4115-4a60-9692-00463a065139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 14s 18ms/step - loss: 0.3175 - accuracy: 0.8704\n",
      "Test acc: 0.870\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"attention.keras\")\n",
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
