{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNpKJmU7A8r3JXi/Mvpp+ur",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erinijapranckeviciene/MF54609_18981_1_20241/blob/main/A_Geron_book_Chapter_17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GAN Generative adversarial network\n",
        "\n",
        "Example on Fashion MNIST dataset p.661\n",
        "\n",
        "...\"Let’s go ahead and build a simple GAN for Fashion MNIST.\n",
        "First, we need to build the generator and the discriminator. The generator is similar\n",
        "to an autoencoder’s decoder, and the discriminator is a regular binary classifier:\n",
        "it takes an image as input and ends with a Dense layer containing a single unit\n",
        "and using the sigmoid activation function. For the second phase of each training\n",
        "iteration, we also need the full GAN model containing the generator followed by the\n",
        "discriminator:\"..."
      ],
      "metadata": {
        "id": "kq9IquybZuNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras as keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Textbook does not have input layer\n",
        "\n",
        "codings_size = 30\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "Dense = tf.keras.layers.Dense\n",
        "generator = tf.keras.Sequential([\n",
        "# Input and shape were required\n",
        "keras.layers.InputLayer((codings_size,) ), #added - but waht it does?\n",
        "# The above line was added to the textbook code\n",
        "\n",
        "Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
        "Dense(150, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
        "Dense(28 * 28, activation=\"sigmoid\"),\n",
        "tf.keras.layers.Reshape([28, 28])\n",
        "])\n",
        "\n",
        "discriminator = tf.keras.Sequential([\n",
        "tf.keras.layers.Flatten(),\n",
        "Dense(150, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
        "Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
        "Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "gan = tf.keras.Sequential([generator, discriminator])\n",
        "gan.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "B3IeAkgXaRgR",
        "outputId": "f24b8688-dbe9-41a5-a405-be7fded9611a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential (\u001b[38;5;33mSequential\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m)              │         \u001b[38;5;34m136,634\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ sequential_1 (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │         \u001b[38;5;34m132,951\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">136,634</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ sequential_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">132,951</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m269,585\u001b[0m (1.03 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">269,585</span> (1.03 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m269,585\u001b[0m (1.03 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">269,585</span> (1.03 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "...\"Next, we need to compile these models. As the discriminator is a binary classifier,\n",
        "we can naturally use the binary cross-entropy loss. The gan model is also a binary\n",
        "classifier, so it can use the binary cross-entropy loss as well. However, the generator\n",
        "will only be trained through the gan model, so we do not need to compile it at all.\n",
        "Importantly, the discriminator should not be trained during the second phase, so we\n",
        "make it non-trainable before compiling the gan model:\"..."
      ],
      "metadata": {
        "id": "ziybqkAtdfrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "discriminator.trainable = False\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
      ],
      "metadata": {
        "id": "PnNX32yPdgoB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "...\"Since the training loop is unusual, we cannot use the regular fit() method. Instead,\n",
        "we will write a custom training loop. For this, we first need to create a Dataset to\n",
        "iterate through the images:\"..."
      ],
      "metadata": {
        "id": "_6UYzYm6iISS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The code is added to this snippet in the textbook\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "X_train = X_train.astype(np.float32) / 255\n",
        "X_test = X_test.astype(np.float32) / 255\n",
        "# The dataset import is added\n",
        "\n",
        "batch_size = 32\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(buffer_size=1000)\n",
        "print(X_train.shape)\n",
        "print(\"dataset shuffle\")\n",
        "print(dataset)\n",
        "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)\n",
        "print(\"dataset prefetch\")\n",
        "print(dataset)\n",
        "print(len(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gs8wmHjiMNj",
        "outputId": "cc4607d3-c971-4a18-de3a-72b989a6b37d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "dataset shuffle\n",
            "<_ShuffleDataset element_spec=TensorSpec(shape=(28, 28), dtype=tf.float32, name=None)>\n",
            "dataset prefetch\n",
            "<_PrefetchDataset element_spec=TensorSpec(shape=(32, 28, 28), dtype=tf.float32, name=None)>\n",
            "1875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m9XhQgVyoVtc"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "...\"We are now ready to write the training loop. Let’s wrap it in a train_gan() function.\n",
        "\n",
        "As discussed earlier, you can see the two phases at each iteration:\n",
        "  - In phase one we feed Gaussian noise to the generator to produce fake images,\n",
        "and we complete this batch by concatenating an equal number of real images.\n",
        "The targets y1 are set to 0 for fake images and 1 for real images. Then we train\n",
        "the discriminator on this batch. Remember that the discriminator is trainable in\n",
        "this phase, but we are not touching the generator.\n",
        "  - In phase two, we feed the GAN some Gaussian noise. Its generator will start by\n",
        "producing fake images, then the discriminator will try to guess whether these\n",
        "images are fake or real. In this phase, we are trying to improve the generator,\n",
        "which means that we want the discriminator to fail: this is why the targets y2 are\n",
        "all set to 1, although the images are fake. In this phase, the discriminator is not\n",
        "trainable, so the only part of the gan model that will improve is the generator."
      ],
      "metadata": {
        "id": "yXducAKrkSE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan(gan, dataset, batch_size, codings_size, n_epochs):\n",
        "  generator, discriminator = gan.layers\n",
        "  for epoch in range(n_epochs):\n",
        "    print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))\n",
        "    batch_count = 0\n",
        "    for X_batch in dataset:\n",
        "    # phase 1 - training the discriminator\n",
        "      batch_count += 1\n",
        "      if batch_count % 500 == 0:\n",
        "        print(batch_count)\n",
        "      noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "\n",
        "      generated_images = generator(noise)\n",
        "      X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
        "      y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
        "      discriminator.train_on_batch(X_fake_and_real, y1)\n",
        "      # phase 2 - training the generator\n",
        "      noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "\n",
        "      y2 = tf.constant([[1.]] * batch_size)\n",
        "      gan.train_on_batch(noise, y2)"
      ],
      "metadata": {
        "id": "W7lgRl9WkSkq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Takes a lot of time to train !**"
      ],
      "metadata": {
        "id": "1kaOe62B8l0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_gan(gan, dataset, batch_size, codings_size, n_epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vrn_yeSHlDlE",
        "outputId": "7692244b-b817-430d-bb78-77499bb85a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "500\n",
            "1000\n",
            "1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "...\"That’s it! After training, you can randomly sample some codings from a Gaussian\n",
        "distribution, and feed them to the generator to produce new images:\"..."
      ],
      "metadata": {
        "id": "1g7daoQ84Tyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "codings = tf.random.normal(shape=[batch_size, codings_size])\n",
        "generated_images = generator.predict(codings)"
      ],
      "metadata": {
        "id": "wzQKNNTm4vs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "...\"If you display the generated images (see Figure 17-15), you will see that at the end of\n",
        "the first epoch, they already start to look like (very noisy) Fashion MNIST images.\"..."
      ],
      "metadata": {
        "id": "j4IjjYhO4-Vo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-kUor-1I5Bgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "E1Gcn4sddsTT"
      }
    }
  ]
}