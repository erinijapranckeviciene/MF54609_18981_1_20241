{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOLvRr5pHe7FVd99HRn/pwi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erinijapranckeviciene/MF54609_18981_1_20241/blob/main/FC_book_Ch_12_Variational_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oc9Za6XbBmpc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generative deep learning"
      ],
      "metadata": {
        "id": "yh2UptJvBqbI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 12.4.4 Implementing a VAE with Keras (F.Collet book page 396)\n",
        "\n",
        "...\" We’re going to be implementing a VAE that can generate MNIST digits. It’s going to\n",
        "have three parts:\n",
        "  - An encoder network that turns a real image into a mean and a variance in the\n",
        "latent space\n",
        "  - A sampling layer that takes such a mean and variance, and uses them to sample\n",
        "a random point from the latent space\n",
        "  - A decoder network that turns points from the latent space back into images\n",
        "  \n",
        "The following listing shows the encoder network we’ll use, mapping images to the\n",
        "parameters of a probability distribution over the latent space. It’s a simple convnet\n",
        "that maps the input image x to two vectors, z_mean and z_log_var. One important\n",
        "detail is that we use strides for downsampling feature maps instead of max pooling.\n",
        "The last time we did this was in the image segmentation example in chapter 9. Recall\n",
        "that, in general, strides are preferable to max pooling for any model that cares about\n",
        "information location—that is to say, where stuff is in the image—and this one does, since\n",
        "it will have to produce an image encoding that can be used to reconstruct a valid\n",
        "image.\n",
        "\"...\n",
        "\n"
      ],
      "metadata": {
        "id": "l4MaPAoYBvM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 12.24 VAE encoder network\n",
        "\n",
        "# Use https://keras.io/examples/generative/vae/\n",
        "\n",
        "The code from the textbook does not run."
      ],
      "metadata": {
        "id": "sAoA0nLP65YW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CUUDRdrMVOMf"
      }
    }
  ]
}