{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "41375591-b8c2-4b9f-997b-2156eb71c126",
      "metadata": {
        "id": "41375591-b8c2-4b9f-997b-2156eb71c126"
      },
      "source": [
        "# Text processing with RNN using IMDB reviews dataset.\n",
        "\n",
        "#### Run cells and answer following questions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b4fb87b-6c66-475f-a1f9-2be95ffc6686",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "3b4fb87b-6c66-475f-a1f9-2be95ffc6686"
      },
      "source": [
        "## Question 1:\n",
        "\n",
        "#### The dense model below was built using 1 Ngram model and classification accuracy on test data achieved is ~0.888. Reuse the same model with 2 Ngram option. What do you have to change? What accuracy do you achieve on test data? Is it better or worse than 1 Ngram?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "830da14c-1343-4dcc-a507-83426e4651a0",
      "metadata": {
        "id": "830da14c-1343-4dcc-a507-83426e4651a0"
      },
      "source": [
        "## Question 2:\n",
        "\n",
        "#### Find the funtion to retrieve the created vocabulary ( reference: https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization). Retrieve vocabulary for 2 Ngram model and display and count how many times you see a phrase that contains word 'terrible'.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcbbca10-83c0-470e-8649-7ffebebab637",
      "metadata": {
        "id": "fcbbca10-83c0-470e-8649-7ffebebab637"
      },
      "source": [
        "## Question 3:\n",
        "\n",
        "#### In the last part with MultiHeadAttention layer what regularization method could we use to reduce training when performance starts oscilating on the validation set?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfda8f00-dc60-4a5a-9a07-62760759945f",
      "metadata": {
        "id": "dfda8f00-dc60-4a5a-9a07-62760759945f"
      },
      "source": [
        "## Question 4 optional:\n",
        "\n",
        "#### In the last part it would be interesting to access and inspect Embedding and MultiHeadAttention layers to understand their structure. But the IMDB dataset is very complex. How can we create a very simple two or four sentences dataset to work with the model and how to access those layers to inspect their weights? The most important thing is that we understand why we are choosing one or the other architecture.     "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download IMDB data from github and unpack it"
      ],
      "metadata": {
        "id": "28wtnM36HdNS"
      },
      "id": "28wtnM36HdNS"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/erinijapranckeviciene/MF54609_18981_1_20241/raw/refs/heads/main/datasets/RNN/aclImdb.zip"
      ],
      "metadata": {
        "id": "GQ_yDsgWHkQv",
        "outputId": "cb12b97a-4206-478d-993c-2a5f9e5d0d3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GQ_yDsgWHkQv",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-14 23:25:15--  https://github.com/erinijapranckeviciene/MF54609_18981_1_20241/raw/refs/heads/main/datasets/RNN/aclImdb.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/erinijapranckeviciene/MF54609_18981_1_20241/refs/heads/main/datasets/RNN/aclImdb.zip [following]\n",
            "--2025-01-14 23:25:16--  https://raw.githubusercontent.com/erinijapranckeviciene/MF54609_18981_1_20241/refs/heads/main/datasets/RNN/aclImdb.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 73380778 (70M) [application/zip]\n",
            "Saving to: ‘aclImdb.zip’\n",
            "\n",
            "aclImdb.zip         100%[===================>]  69.98M  87.1MB/s    in 0.8s    \n",
            "\n",
            "2025-01-14 23:25:18 (87.1 MB/s) - ‘aclImdb.zip’ saved [73380778/73380778]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq aclImdb.zip"
      ],
      "metadata": {
        "id": "ufoyHae6HtAj"
      },
      "id": "ufoyHae6HtAj",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e779907c-2969-4cde-aaac-8cb9bd78e295",
      "metadata": {
        "id": "e779907c-2969-4cde-aaac-8cb9bd78e295"
      },
      "source": [
        "## Prepare IMDB data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "71a7ee70-e2cc-43d9-bbcf-fb4147f3c0c2",
      "metadata": {
        "id": "71a7ee70-e2cc-43d9-bbcf-fb4147f3c0c2",
        "outputId": "bc21bdc7-08d8-423d-87f3-30033fa0d608",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import os, pathlib, shutil, random\n",
        "from tensorflow import keras\n",
        "\n",
        "batch_size = 32\n",
        "train_ds = keras.utils.text_dataset_from_directory(\"aclImdb/train\", batch_size=batch_size )\n",
        "val_ds = keras.utils.text_dataset_from_directory(\"aclImdb/val\", batch_size=batch_size)\n",
        "test_ds = keras.utils.text_dataset_from_directory(\"aclImdb/test\", batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95a74a99-e19c-40a0-8ca0-1e71711319b5",
      "metadata": {
        "id": "95a74a99-e19c-40a0-8ca0-1e71711319b5"
      },
      "source": [
        "#### Inspect the dataset read from directory files\n",
        "Displaying the shapes and dtypes of the first batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "87d94172-d37b-45d0-b9be-81f1d488fa97",
      "metadata": {
        "id": "87d94172-d37b-45d0-b9be-81f1d488fa97",
        "outputId": "988c4b8e-927a-4202-d826-9561f6087b0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32,)\n",
            "inputs.dtype: <dtype: 'string'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor(b\"I just caught an episode about Brad, the crack cocaine addict who turned to a drug addicted life on the streets after his bicycle racing career went to shambles as fast as it started. I have to say that the story about his biking career was more heart-breaking than his drug addiction. Here's this young guy who is winning bike races left and right and is invited to train with an Olympic training team for two weeks, and immediately upon arriving he insults Lance Armstrong, one of the greatest athletes who ever lived, and is generally callous and unfriendly to everyone in general. Understandably, he is soon asked to leave. Most of the show is about his struggle with addiction and how he got his life back, but what I wanted to know was what was wrong with him in the first place to make his act like such an ass?<br /><br />At any rate, I was confused about how the show was put together, since it shows Brad at the height of his addiction. We see footage of him pan-handling and sleeping in gutters and ditches and even smoking crack cocaine. I didn't even know that was legal to show, but why would a camera crew just follow him around and film that? Do they do that in hopes that this guy will turn his life around and give them some material for a good TV episode?<br /><br />At any rate, it is an enlightening show, because it shows the effects of various addictions and the total control that they can take over people's lives. Sometimes it's hard to watch because you really see how badly the families and friends suffer in the face of the addict's indifference, although I have to admit that at the end it all seems a little too clean-cut. There are times during the episodes when terrible things happen and everything seems lost, but still, and maybe I should warn about spoilers here, everything has a little too much of a happily-ever-after feel at the end, and I have a feeling that that is a very uncommon occurrence in real life. But still, it's a show about people trying to help other people, and you can never complain too much about something like that\\xc2\\x85\", shape=(), dtype=string)\n",
            "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67cf5dac-c429-480a-9545-7d20d1f3bfb9",
      "metadata": {
        "id": "67cf5dac-c429-480a-9545-7d20d1f3bfb9"
      },
      "source": [
        "#### Keep only text in text_only_train_ds. Use only text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c1f00f27-1536-48d0-b944-c749a0433e1a",
      "metadata": {
        "id": "c1f00f27-1536-48d0-b944-c749a0433e1a",
        "outputId": "7057c259-ff7a-4057-a4d7-59e13f692178",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32,)\n",
            "inputs.dtype: <dtype: 'string'>\n",
            "inputs[0]: tf.Tensor(b'What I liked best in this film is that like the films of Hitchcock, it is a thriller that does not take itself too seriously.<br /><br />Hitchcock understood that people go the the movies to have a good time. Something that Hollywood seems to have forgotten in recent years. This is a thriller, but it has plenty of laughs and always has one eye winking at the camera.<br /><br />Rachel McAdams is wonderful as always. Cillian Murphy is creepier than he was in Batman Begins. In the old days, there were guys who always played the bad guy. We don\\'t see much of that these days because I suspect the Hollywood agents consider it a bad career move, but Cillian Murphy is really good at being bad.<br /><br />The directing is surprising stylish. The story is good but the dialog could have used some sprucing up.<br /><br />\"Red Eye\" is a really fun film and people were applauding when the closing credits started rolling. If you are in the mood for an enjoyable escapist thriller, \"Red Eye\" might be your ticket.', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "# This function returns only data part without target\n",
        "# to create a new dataset that will be used to create dictionary\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
        "for inputs in text_only_train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4a904102-ae81-4b24-bd9a-edca24f87851",
      "metadata": {
        "id": "4a904102-ae81-4b24-bd9a-edca24f87851"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "# Text vectorization layer creates a structure that will populate with textual data\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization\n",
        "# This layer performs text standardization, splitting it into Ngrams - single or pairs of words\n",
        "# It prepares output according to output mode\n",
        "text_vectorization = TextVectorization( max_tokens=20000, output_mode=\"multi_hot\")\n",
        "\n",
        "# Use text_only_train_ds to create a dictionary of words that are in IMDB reviews,\n",
        "# the vocabulary is limited by 20000 (adapt() method)\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "# Here datasets are created where the text in the string is converted\n",
        "# to the representation of 20000 dimensional vectors in which a presence of word in\n",
        "# the text is marked by 1 and absence by 0. This is done for train, validation and test.\n",
        "binary_1gram_train_ds = train_ds.map( lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
        "binary_1gram_val_ds = val_ds.map( lambda x, y: (text_vectorization(x), y),num_parallel_calls=4)\n",
        "binary_1gram_test_ds = test_ds.map( lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1cce6611-6109-4549-813c-2b313be7818d",
      "metadata": {
        "id": "1cce6611-6109-4549-813c-2b313be7818d",
        "outputId": "ffb2d44c-7564-49ca-cbbe-e6316cc7cfc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32, 20000)\n",
            "inputs.dtype: <dtype: 'int64'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor([1 1 1 ... 0 0 0], shape=(20000,), dtype=int64)\n",
            "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in binary_1gram_train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6dbe81e-093b-416a-9518-fdadab483eaf",
      "metadata": {
        "id": "f6dbe81e-093b-416a-9518-fdadab483eaf"
      },
      "source": [
        "#### This is function creates model from Listing 11.5\n",
        "Our model-building utility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "712388fd-69bb-46f1-bc5a-e9e1e4fcc960",
      "metadata": {
        "id": "712388fd-69bb-46f1-bc5a-e9e1e4fcc960"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# This is dense model\n",
        "def get_model(max_tokens=20000, hidden_dim=16):\n",
        "    inputs = keras.Input(shape=(max_tokens,))\n",
        "    x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "935fbf5e-edf7-49a9-a0d5-d8170fb580b0",
      "metadata": {
        "id": "935fbf5e-edf7-49a9-a0d5-d8170fb580b0",
        "outputId": "10f09b05-c8cc-413d-ebc2-58312042eb12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20000\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │         \u001b[38;5;34m320,016\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">320,016</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m320,033\u001b[0m (1.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,033</span> (1.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m320,033\u001b[0m (1.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,033</span> (1.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = get_model()\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8988a824-2cab-4785-827d-50bf2177af53",
      "metadata": {
        "id": "8988a824-2cab-4785-827d-50bf2177af53"
      },
      "source": [
        "#### Training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b102d314-fb12-4597-b908-90c8a5e345b0",
      "metadata": {
        "id": "b102d314-fb12-4597-b908-90c8a5e345b0",
        "outputId": "16402863-be8c-45df-ca9a-84f904e3a778",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x780a795fab30>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# cache() is a dataset method that saves the dataset elements in memory or disk and reuses them when called\n",
        "callbacks = [ keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\", save_best_only=True) ]\n",
        "model.fit(binary_1gram_train_ds.cache(), validation_data=binary_1gram_val_ds.cache(), verbose=0, epochs=10, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "850fdbf9-6376-4c5b-b16d-061bdb8bb17a",
      "metadata": {
        "id": "850fdbf9-6376-4c5b-b16d-061bdb8bb17a",
        "outputId": "77357865-0b63-46e3-ebf6-6f48946559d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m498s\u001b[0m 635ms/step - accuracy: 0.8897 - loss: 0.2896\n",
            "Test acc: 0.888\n"
          ]
        }
      ],
      "source": [
        "# Accuracy on test data\n",
        "model = keras.models.load_model(\"binary_1gram.keras\")\n",
        "print(f\"Test acc: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8eb5066a-533d-431d-b24d-3aca4361a22a",
      "metadata": {
        "id": "8eb5066a-533d-431d-b24d-3aca4361a22a"
      },
      "source": [
        "## Different output mode -  integer sequence datasets\n",
        "\n",
        "#### LSTM layer with 4 units gives worse that 2 Ngram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9ad80d17-a24d-45eb-bdfd-4380d91ffcec",
      "metadata": {
        "id": "9ad80d17-a24d-45eb-bdfd-4380d91ffcec"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# max_length is a length of the vector that encodes text\n",
        "# 250 size gave ~0.85 on test data\n",
        "# 600 with 4 LSTM units does not train at all\n",
        "# the reviews are about 300 words\n",
        "max_length = 300\n",
        "max_tokens = 20000\n",
        "text_vectorization = layers.TextVectorization( max_tokens=max_tokens, output_mode=\"int\", output_sequence_length=max_length)\n",
        "\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
        "int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
        "int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c5e159f4-82f5-4552-aa93-ef84fdad4af1",
      "metadata": {
        "id": "c5e159f4-82f5-4552-aa93-ef84fdad4af1",
        "outputId": "74f52311-b576-4e55-cb44-0902f03c65f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 300)\n",
            "tf.Tensor(\n",
            "[   11   482     7  1006   384     3     2   538   112     2   354    26\n",
            "     4   164  6358     3  1411    66   838  3140    17   252    82    30\n",
            "    73    51   937     3    81    69  2147     6     9    30    73    51\n",
            "  1783     3   896    21     4   158   662    71    82  3656  4020    21\n",
            "   354     3    66   456    39   384     3     2   538 12372  2744    13\n",
            "    13   879  8317     1     7     4  7013    17     4   463  1053    55\n",
            "   183    73    51  4541     3  3460 10134    71     2   340     5    40\n",
            "   458   350    55     7  1903    17     2   342     5    40  1121  1530\n",
            "    36    14    40  3168   133 15112    25  2381  7751    21    40    40\n",
            " 15904  1623     3  1978     3  1116   310  2701    40   971  1419    52\n",
            "    74    13    13     1     1     4  4491     7  8393  1319    17  3055\n",
            "   139     5    40   358   672    37  4261     3    53     4  2188  2942\n",
            "   726   261    34   597     8    40    55     7  1050   895     6    83\n",
            "     4   661   808    33    40   350    36  1395    12    55   204   142\n",
            "    78  3912   986     2   643     3  2259 19645   137   192   726     3\n",
            "     1    24   460   162     9     7   217     6   887    12   726  1565\n",
            "    40    46     2   265    55   204     4  3004    37     2  4261  2011\n",
            "    16    40  2947     1    68    49    25  3057    24    13    13     1\n",
            "  9203     4  2317     7  5255    58     5    40  2947   113   245  6737\n",
            "    63    60  4525   912   245    15    35    24   250  1073     1     3\n",
            "    55   929   704    16    40  8053    36  1437    25  6749     4   110\n",
            "   100  8413     6    40     3    55   121    22  9948    16     1    76\n",
            "   217     6    68   702    55    76  1657    40  1635    41  9351    58\n",
            "    17    40   672   251    33     1  3971  2872     4   146  3564   986\n",
            "   243     7   683     3     7   816   351    55     1     4  2500  1705], shape=(300,), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in int_train_ds:\n",
        "    print(inputs.shape)\n",
        "    print(inputs[0])\n",
        "    print(targets[0])\n",
        "    # With this test_input variable verify tf.one_hot() transformation\n",
        "    test_input=inputs[0]\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6a04cee-0005-496a-9c60-bd534888d200",
      "metadata": {
        "id": "a6a04cee-0005-496a-9c60-bd534888d200"
      },
      "source": [
        "#### Try RNN for text classification using integer feature vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "dd6227db-8275-4e18-8881-e210aa834266",
      "metadata": {
        "id": "dd6227db-8275-4e18-8881-e210aa834266",
        "outputId": "00cf1296-2aa1-4896-c517-b5213d20611b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(300, 20000), dtype=float32, numpy=\n",
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "tf.one_hot(test_input, depth=max_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "0a550ec6-738d-4a54-9753-ddc974257b5e",
      "metadata": {
        "id": "0a550ec6-738d-4a54-9753-ddc974257b5e",
        "outputId": "e1a036e3-d70e-436e-c33e-a083b7c71b28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<KerasTensor shape=(None, None, 20000), dtype=float32, sparse=False, name=keras_tensor_18>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_8 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ one_hot (\u001b[38;5;33mOneHot\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20000\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │         \u001b[38;5;34m800,440\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m11\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ one_hot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">OneHot</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">800,440</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m800,451\u001b[0m (3.05 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">800,451</span> (3.05 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m800,451\u001b[0m (3.05 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">800,451</span> (3.05 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# The sizes of layers are minimized in order to run\n",
        "import tensorflow as tf\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "# Here will be binary input as test_input\n",
        "\n",
        "embedded = tf.keras.ops.one_hot(inputs, num_classes=max_tokens)\n",
        "print(embedded)\n",
        "\n",
        "# RNN layer\n",
        "# NOT USE TOO BIG MODEL : x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "# When units=4 the model runs.\n",
        "x = layers.LSTM(10)(embedded)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "dc5c6353-38fd-4d28-a007-b3d3638d7cc0",
      "metadata": {
        "id": "dc5c6353-38fd-4d28-a007-b3d3638d7cc0"
      },
      "outputs": [],
      "source": [
        "callbacks = [ keras.callbacks.ModelCheckpoint(\"int_lstm.keras\", save_best_only=True) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "da28a0b0-0953-4a36-8558-9b966ba90dbf",
      "metadata": {
        "id": "da28a0b0-0953-4a36-8558-9b966ba90dbf",
        "outputId": "d2eb425b-f960-4e67-a421-c092d23a82a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 68ms/step - accuracy: 0.5161 - loss: 0.6921 - val_accuracy: 0.6316 - val_loss: 0.6517\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 67ms/step - accuracy: 0.6459 - loss: 0.6515 - val_accuracy: 0.7078 - val_loss: 0.6085\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 70ms/step - accuracy: 0.7311 - loss: 0.5790 - val_accuracy: 0.7872 - val_loss: 0.5143\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 68ms/step - accuracy: 0.7998 - loss: 0.5066 - val_accuracy: 0.8372 - val_loss: 0.4449\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 68ms/step - accuracy: 0.8291 - loss: 0.4621 - val_accuracy: 0.8422 - val_loss: 0.4273\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 67ms/step - accuracy: 0.8352 - loss: 0.4511 - val_accuracy: 0.8418 - val_loss: 0.4303\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 68ms/step - accuracy: 0.8485 - loss: 0.4229 - val_accuracy: 0.8536 - val_loss: 0.4012\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 66ms/step - accuracy: 0.8591 - loss: 0.4026 - val_accuracy: 0.8416 - val_loss: 0.4546\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 68ms/step - accuracy: 0.8790 - loss: 0.3636 - val_accuracy: 0.8610 - val_loss: 0.3989\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 68ms/step - accuracy: 0.8924 - loss: 0.3320 - val_accuracy: 0.8668 - val_loss: 0.3659\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x780a701aafb0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, verbose=1, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c4768d8c-f61f-4bf2-ba39-e150905fe64f",
      "metadata": {
        "id": "c4768d8c-f61f-4bf2-ba39-e150905fe64f",
        "outputId": "dc212ddd-02bc-45a6-ff55-c6b155dc768c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - accuracy: 0.8545 - loss: 0.3942\n",
            "Test acc: 0.855\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.load_model(\"int_lstm.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "cc688cfd-e185-4428-b0c3-8ea840d24896",
      "metadata": {
        "id": "cc688cfd-e185-4428-b0c3-8ea840d24896",
        "outputId": "f48f2004-2acf-4ab7-fb33-3cfc7afcdfb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step\n"
          ]
        }
      ],
      "source": [
        "pred=model.predict(int_test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "883ddcd9-8ffa-4be3-85fd-3909e0b41434",
      "metadata": {
        "id": "883ddcd9-8ffa-4be3-85fd-3909e0b41434",
        "outputId": "cfc10c06-82d0-4fc0-f8ea-6bcec7b19486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.50074637]\n",
            " [0.9223024 ]\n",
            " [0.92039317]\n",
            " ...\n",
            " [0.10627599]\n",
            " [0.04852633]\n",
            " [0.9195446 ]]\n"
          ]
        }
      ],
      "source": [
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "3bdbaba0-e6ab-482b-95ca-504510d7551a",
      "metadata": {
        "id": "3bdbaba0-e6ab-482b-95ca-504510d7551a",
        "outputId": "67952f1d-32ec-421a-c73f-759fb42ffdd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 ... 0 0 0]\n",
            "[array([0, 1]), array([13013, 11987])]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "predicted=np.array([int(x>0.5) for x in np.concatenate(pred) ] )\n",
        "print(predicted)\n",
        "unique, counts = np.unique(predicted, return_counts=True)\n",
        "print([unique, counts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "1c430f23-5a70-4fa4-8b76-04e01739f218",
      "metadata": {
        "id": "1c430f23-5a70-4fa4-8b76-04e01739f218",
        "outputId": "399ca8d4-0fa1-4fde-9929-f68db881fac0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 1 0 0]\n",
            "[array([0, 1]), array([12500, 12500])]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# This displays the contents of the dataset\n",
        "# list(int_test_ds)\n",
        "# Collect targets to use in confusion table\n",
        "target_arr=[]\n",
        "for inputs, targets in int_test_ds:\n",
        "    target=[int(x) for x in targets]\n",
        "    target_arr.append(target)\n",
        "\n",
        "actual=np.concatenate(target_arr)\n",
        "print(actual)\n",
        "unique, counts = np.unique(actual, return_counts=True)\n",
        "print([unique, counts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "545f8928-7fa7-4c84-bc64-a0ed544f0c04",
      "metadata": {
        "id": "545f8928-7fa7-4c84-bc64-a0ed544f0c04",
        "outputId": "5865fd57-4cdb-44cb-e0d8-9cea65ead8e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[6534, 5966],\n",
              "       [6479, 6021]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# show confusion table\n",
        "# Why confusion table shows different accuracy than accuracy of model evaluate?\n",
        "# Need to investigate, but leaving it for later now.\n",
        "tf.math.confusion_matrix(actual, predicted)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c4321d6-0aad-43ea-b4e7-dd40c65c8d13",
      "metadata": {
        "id": "3c4321d6-0aad-43ea-b4e7-dd40c65c8d13"
      },
      "source": [
        "#### Try to use Enbedding layer for the previous problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "6e5ae1b7-b150-4e71-b36d-d2a50af015c2",
      "metadata": {
        "id": "6e5ae1b7-b150-4e71-b36d-d2a50af015c2",
        "outputId": "22b991a8-81dc-4615-b9c0-198da76ec0e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_9 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │       \u001b[38;5;34m5,120,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)                  │          \u001b[38;5;34m40,880\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m36\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">40,880</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,160,916\u001b[0m (19.69 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,160,916</span> (19.69 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,160,916\u001b[0m (19.69 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,160,916</span> (19.69 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "vocab_size = 20000\n",
        "embed_dim = 256\n",
        "\n",
        "# ignore from FC book Ch.11 Listing 11.22\n",
        "#num_heads = 2\n",
        "#dense_dim = 32\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = layers.Embedding(vocab_size, embed_dim)(inputs)\n",
        "\n",
        "x = layers.LSTM(35)(x)\n",
        "\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "# Maybe optimizer could be different?\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "5a543783-1c36-418a-a4fc-3480e34873f4",
      "metadata": {
        "id": "5a543783-1c36-418a-a4fc-3480e34873f4",
        "outputId": "2ebf7de8-32f8-45a4-e278-51813dc728b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 25ms/step - accuracy: 0.5097 - loss: 0.6942 - val_accuracy: 0.5048 - val_loss: 0.6947\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.5269 - loss: 0.6915 - val_accuracy: 0.5084 - val_loss: 0.6934\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - accuracy: 0.5291 - loss: 0.6885 - val_accuracy: 0.5122 - val_loss: 0.6957\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - accuracy: 0.5471 - loss: 0.6813 - val_accuracy: 0.5252 - val_loss: 0.6879\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.5614 - loss: 0.6641 - val_accuracy: 0.5518 - val_loss: 0.6642\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.5774 - loss: 0.6458 - val_accuracy: 0.5598 - val_loss: 0.6546\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.6221 - loss: 0.6075 - val_accuracy: 0.7644 - val_loss: 0.5304\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.8071 - loss: 0.4808 - val_accuracy: 0.7118 - val_loss: 0.6577\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.8026 - loss: 0.4779 - val_accuracy: 0.8086 - val_loss: 0.4887\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.8420 - loss: 0.4173 - val_accuracy: 0.7894 - val_loss: 0.5137\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7809fb151690>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "callbacks = [ keras.callbacks.ModelCheckpoint(\"int_embed_lstm.keras\", save_best_only=True) ]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, verbose=1, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "35c81333-bf99-4133-890a-d0f2770655fd",
      "metadata": {
        "id": "35c81333-bf99-4133-890a-d0f2770655fd",
        "outputId": "baea6854-93fe-4f24-a2df-239b90bc787b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8047 - loss: 0.4942\n",
            "Test acc: 0.801\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.load_model(\"int_embed_lstm.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a976e038-b600-4d5f-a90c-7febde85996a",
      "metadata": {
        "id": "a976e038-b600-4d5f-a90c-7febde85996a"
      },
      "source": [
        "### The more complex architecture the poorer results are"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156900ad-5156-4836-bee8-756853109138",
      "metadata": {
        "id": "156900ad-5156-4836-bee8-756853109138"
      },
      "source": [
        "#### Model that uses Encoder and MultiHeadAttention layers ( by some analogy to Listing 11.22 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "9e6782b0-74ce-49af-a447-73a39f62a7c3",
      "metadata": {
        "id": "9e6782b0-74ce-49af-a447-73a39f62a7c3",
        "outputId": "6a242841-8d47-4844-a402-b7fddfdc3002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_10            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m5,120,000\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m1,314,816\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_max_pooling1d      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ global_max_pooling1d[\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m257\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_10            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,000</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,314,816</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_max_pooling1d      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,435,073\u001b[0m (24.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,435,073</span> (24.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,435,073\u001b[0m (24.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,435,073</span> (24.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# What can we do to improve? Here we dont have any RNN, just transformations\n",
        "\n",
        "vocab_size = 20000\n",
        "embed_dim = 256\n",
        "\n",
        "# from FC book Ch.11 Listing 11.22\n",
        "# num_heads = 2 - acheved 8.69\n",
        "# Lets try more heads/words\n",
        "# With 4 heads 8.73 , just a bit , with 5 heads 8.70\n",
        "# Still worse than a simpler method.\n",
        "num_heads = 5\n",
        "dense_dim = 32\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = layers.Embedding(vocab_size, embed_dim)(inputs)\n",
        "\n",
        "# try to add attention\n",
        "x = layers.MultiHeadAttention( num_heads=num_heads, key_dim=embed_dim)(x,x)\n",
        "\n",
        "# This layer is needed - what it does?\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29275d7d-bd8e-4471-b5cb-8e1a98c039e0",
      "metadata": {
        "id": "29275d7d-bd8e-4471-b5cb-8e1a98c039e0"
      },
      "source": [
        "#### Use model with attention , it really improved from previous, but not compared to more simple model of 2 Ngram.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "f103cc80-1ae9-4d98-92fa-f0546e9cc4f4",
      "metadata": {
        "id": "f103cc80-1ae9-4d98-92fa-f0546e9cc4f4",
        "outputId": "f4289c16-3ab1-4a8b-e29e-89a4914c300b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 58ms/step - accuracy: 0.5084 - loss: 0.6942 - val_accuracy: 0.5000 - val_loss: 0.6940\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 57ms/step - accuracy: 0.5202 - loss: 0.6926 - val_accuracy: 0.5836 - val_loss: 0.6548\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 58ms/step - accuracy: 0.6555 - loss: 0.6213 - val_accuracy: 0.8152 - val_loss: 0.4337\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 57ms/step - accuracy: 0.7776 - loss: 0.4691 - val_accuracy: 0.8428 - val_loss: 0.3689\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 56ms/step - accuracy: 0.8252 - loss: 0.3889 - val_accuracy: 0.7776 - val_loss: 0.4559\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 57ms/step - accuracy: 0.8482 - loss: 0.3501 - val_accuracy: 0.8646 - val_loss: 0.3240\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 57ms/step - accuracy: 0.8642 - loss: 0.3241 - val_accuracy: 0.8638 - val_loss: 0.3159\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 57ms/step - accuracy: 0.8772 - loss: 0.3012 - val_accuracy: 0.8686 - val_loss: 0.3131\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 57ms/step - accuracy: 0.8817 - loss: 0.2848 - val_accuracy: 0.8800 - val_loss: 0.3034\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 57ms/step - accuracy: 0.8872 - loss: 0.2712 - val_accuracy: 0.8560 - val_loss: 0.3366\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 57ms/step - accuracy: 0.8992 - loss: 0.2568 - val_accuracy: 0.8772 - val_loss: 0.2936\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 58ms/step - accuracy: 0.9185 - loss: 0.2158 - val_accuracy: 0.8870 - val_loss: 0.2881\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 57ms/step - accuracy: 0.9295 - loss: 0.1919 - val_accuracy: 0.8844 - val_loss: 0.2953\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 57ms/step - accuracy: 0.9358 - loss: 0.1760 - val_accuracy: 0.8862 - val_loss: 0.3042\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 56ms/step - accuracy: 0.9457 - loss: 0.1583 - val_accuracy: 0.8836 - val_loss: 0.3203\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 56ms/step - accuracy: 0.9490 - loss: 0.1436 - val_accuracy: 0.8800 - val_loss: 0.3479\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 54ms/step - accuracy: 0.9587 - loss: 0.1251 - val_accuracy: 0.8750 - val_loss: 0.3931\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 54ms/step - accuracy: 0.9664 - loss: 0.1074 - val_accuracy: 0.8712 - val_loss: 0.4460\n",
            "Epoch 19/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 52ms/step - accuracy: 0.9727 - loss: 0.0842 - val_accuracy: 0.8672 - val_loss: 0.5269\n",
            "Epoch 20/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 51ms/step - accuracy: 0.9813 - loss: 0.0636 - val_accuracy: 0.8646 - val_loss: 0.6384\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7809f3cf7d60>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "callbacks = [ keras.callbacks.ModelCheckpoint(\"attention.keras\", save_best_only=True) ]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=20, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "ca3920ff-4115-4a60-9692-00463a065139",
      "metadata": {
        "id": "ca3920ff-4115-4a60-9692-00463a065139",
        "outputId": "b322cfd7-1bb8-4e7d-c269-a03aa299dc42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.8732 - loss: 0.3030\n",
            "Test acc: 0.875\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.load_model(\"attention.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}